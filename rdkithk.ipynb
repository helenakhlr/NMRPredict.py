{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MolToSmiles\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import os \n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     
     ]
    }
   ],
   "source": [
    "pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to generate molecule images + save them with corresponding lines\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-01' \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-01/'  \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.csv'\n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-02'  \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-02/'  \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.csv'\n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-03'  \n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-03/'  \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-04'  \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-04/'  \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.csv' \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))   \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-05'   \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-05/' \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-06'  \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-06/' \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-07'  \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/orts/images/images_iNEXTG2-Plate-07/' \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orts: iNEXTG2-Plate-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.SDF\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.SDF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"Solvent\"] = \"DMSO\"\n",
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"iNEXT_Lib_1D\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.SDF\"\n",
    "sdf_df.to_csv(\"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png')) \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/orts/images/images_iNEXTG2-Plate-08'  \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/orts/images/images_iNEXTG2-Plate-08/' \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nmrshiftdb2: nmredata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     
    }
   ],
   "source": [
    "params = Chem.SanitizeFlags.SANITIZE_ALL ^ Chem.SanitizeFlags.SANITIZE_PROPERTIES\n",
    "sdf_supplier = Chem.SDMolSupplier('datasets/raw/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.sd', sanitize=True, removeHs=False)\n",
    "\n",
    "mols = []\n",
    "solvent_info = []\n",
    "\n",
    "for mol in sdf_supplier:\n",
    "    if mol is not None:\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        mols.append(smiles)\n",
    "\n",
    "        if 'NMREDATA_SOLVENT' in mol.GetPropsAsDict():\n",
    "            solvent = mol.GetPropsAsDict()['NMREDATA_SOLVENT']\n",
    "        else:\n",
    "            solvent = None\n",
    "        solvent_info.append(solvent)\n",
    "\n",
    "new_data = {\n",
    "    \"SMILES\": mols,\n",
    "    \"SDF present\": \"nmredata\",\n",
    "    \"SDF file path\": \"/data/shared/projects/nmr2structure/datasets/raw/nmrshfitdb2/nmredata/nmrshiftdb2.nmredata.sd\"\n",
    "}\n",
    "new_data[\"NMREDATA_SOLVENT\"] = solvent_info\n",
    "new_df = pd.DataFrame(new_data)\n",
    "new_df.rename(columns={\"NMREDATA_SOLVENT\": \"Solvent\"}, inplace=True)\n",
    "\n",
    "new_df.to_csv(\"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\", index=False, mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:45:53] unsupported number of radical electrons 6\n",
      "[12:53:51] unsupported number of radical electrons 6\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/nmrshiftdb2/nmredata/images.nmredata/'  \n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/nmrshiftdb2/nmredata/images.nmredata/' \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nmrshiftdb2: withsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     
    }
   ],
   "source": [
    "sdf_supplier = Chem.SDMolSupplier(\"datasets/raw/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.sd\")\n",
    "mols = [mol for mol in sdf_supplier if mol is not None]\n",
    "sdf_df = PandasTools.LoadSDF(\"datasets/raw/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df[\"SMILES\"] = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "sdf_df[\"SDF present\"] = \"withsignals\"\n",
    "sdf_df[\"SDF file path\"] = \"/data/shared/projects/nmr2structure/datasets/raw/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.sd\"\n",
    "sdf_df.to_csv(\"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\", index=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
    

     ]
    }
   ],
   "source": [
    "csv_file_path = 'datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def generate_molecule_images(dataframe, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(output_folder, 'molecule_info.txt'), 'w') as out_file:\n",
    "        for index, row in dataframe.iterrows():\n",
    "            smiles = row['SMILES']  \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                img = Draw.MolToImage(mol)\n",
    "                img.save(os.path.join(output_folder, f'molecule_{index}.png'))  \n",
    "                out_file.write(f\"{index}, {smiles}\\n\")\n",
    "\n",
    "output_folder_path = 'datasets/processed/nmrshiftdb2/withsignals/images.withsignals/'  \n",
    "\n",
    "generate_molecule_images(df, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     
     ]
    }
   ],
   "source": [
    "csv_file_path = 'datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_folder = '/data/shared/projects/nmr2structure/datasets/processed/nmrshiftdb2/withsignals/images.withsignals/' \n",
    "df['Image folder location'] = df.index.map(lambda x: os.path.join(image_folder, f'molecule_{x}.png'))\n",
    "\n",
    "updated_csv_file_path = 'datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv'  \n",
    "df.to_csv(updated_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nmrshiftdb2: identical pairs check in nmredata & withsignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical pairs found: 463\n",
      "CSV file 'datasets/processed/nmrshiftdb2/identical_pairs_images.csv' created.\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate hash of image file\n",
    "def calculate_hash(file_path):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        while True:\n",
    "            data = file.read(4096)\n",
    "            if not data:\n",
    "                break\n",
    "            hasher.update(data)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "folder1 = \"datasets/processed/nmrshiftdb2/nmredata/images.nmredata\"\n",
    "folder2 = \"datasets/processed/nmrshiftdb2/withsignals/images.withsignals\"\n",
    "\n",
    "# Initializing dictionaries to store image hashes\n",
    "hashes_folder1 = {}\n",
    "hashes_folder2 = {}\n",
    "\n",
    "# Populating dictionaries w image hashes from folder1\n",
    "for root, _, files in os.walk(folder1):\n",
    "    for file in files:\n",
    "        if file.endswith((\".jpg\", \".png\", \".gif\", \".bmp\")):\n",
    "            file_path = os.path.join(root, file)\n",
    "            image_hash = calculate_hash(file_path)\n",
    "            hashes_folder1[image_hash] = file_path\n",
    "\n",
    "# from folder2\n",
    "for root, _, files in os.walk(folder2):\n",
    "    for file in files:\n",
    "        if file.endswith((\".jpg\", \".png\", \".gif\", \".bmp\")):\n",
    "            file_path = os.path.join(root, file)\n",
    "            image_hash = calculate_hash(file_path)\n",
    "            hashes_folder2[image_hash] = file_path\n",
    "\n",
    "# Find identical image hashes\n",
    "identical_hashes = set(hashes_folder1.keys()) & set(hashes_folder2.keys())\n",
    "\n",
    "csv_filename = \"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\"\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"nmredata\", \"withsignals\"])\n",
    "\n",
    "    for image_hash in identical_hashes:\n",
    "        folder1_image = hashes_folder1.get(image_hash)\n",
    "        folder2_image = hashes_folder2.get(image_hash)\n",
    "        if folder1_image and folder2_image:\n",
    "            image_name1 = os.path.splitext(os.path.basename(folder1_image))[0]\n",
    "            image_name2 = os.path.splitext(os.path.basename(folder2_image))[0]\n",
    "            csv_writer.writerow([image_name1, image_name2])\n",
    "\n",
    "print(f\"Number of identical pairs found: {len(identical_hashes)}\")\n",
    "print(f\"CSV file '{csv_filename}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "\n",
    "def extract_and_add_2(image_name):\n",
    "    try:\n",
    "        number = int(image_name.split('_')[1])\n",
    "        new_number = number + 2\n",
    "        return new_number\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"Original row nmredata\"] = df[\"nmredata\"].apply(extract_and_add_2)\n",
    "df[\"Original row withsignals\"] = df[\"withsignals\"].apply(extract_and_add_2)\n",
    "\n",
    "df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical pairs: 502\n"
     ]
    }
   ],
   "source": [
    "csv_file1 = \"datasets/processed/nmrshiftdb2//nmredata/nmrshiftdb2.nmredata.csv\"\n",
    "csv_file2 = \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\"\n",
    "\n",
    "df1 = pd.read_csv(csv_file1)\n",
    "df2 = pd.read_csv(csv_file2)\n",
    "\n",
    "smiles1 = df1[\"SMILES\"]\n",
    "smiles2 = df2[\"SMILES\"]\n",
    "\n",
    "unique_smiles2 = set(smiles2)\n",
    "\n",
    "identical_pairs_count = 0\n",
    "identical_pairs = []\n",
    "\n",
    "for idx, smile1 in enumerate(smiles1):\n",
    "    mol1 = Chem.MolFromSmiles(smile1)\n",
    "    if mol1:\n",
    "        identical_in_smiles2 = [smile2 for smile2 in unique_smiles2 if smile2 == smile1]\n",
    "        if identical_in_smiles2:\n",
    "            identical_pairs_count += 1\n",
    "            identical_pairs.append((idx, [df2.index[df2[\"SMILES\"] == smile2].tolist() for smile2 in identical_in_smiles2]))\n",
    "\n",
    "print(\"Number of identical pairs:\", identical_pairs_count)\n",
    "\n",
    "identical_pairs_df = pd.DataFrame(identical_pairs, columns=[\"nmredata\", \"withsignals\"])\n",
    "\n",
    "identical_pairs_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "pairs_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs.csv\")\n",
    "\n",
    "def extract_number_withsignals(withsignals):\n",
    "    match = re.search(r'\\[\\[(\\d+)]]', withsignals)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "pairs_df[\"withsignals_number\"] = pairs_df[\"withsignals\"].apply(extract_number_withsignals)\n",
    "\n",
    "unique_number_pairings = set(zip(pairs_df[\"nmredata\"], pairs_df[\"withsignals_number\"]))\n",
    "\n",
    "identical_pairs = []\n",
    "\n",
    "for _, row in images_df.iterrows():\n",
    "    nmredata = row[\"Original row nmredata\"]\n",
    "    withsignals = row[\"Original row withsignals\"]\n",
    "    if (nmredata, withsignals) in unique_number_pairings:\n",
    "        identical_pairs.append({\"nmredata\": nmredata, \"withsignals\": withsignals})\n",
    "\n",
    "identical_pairs_df = pd.DataFrame(identical_pairs)\n",
    "\n",
    "identical_pairs_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_combined.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Image folder location'",
     "output_type": "error",
     "traceback": [
     
     ]
    }
   ],
   "source": [
    "identical_pairs_images_file = \"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\"\n",
    "identical_pairs_images_df = pd.read_csv(identical_pairs_images_file)\n",
    "\n",
    "merged_df = pd.DataFrame(columns=identical_pairs_images_df.columns)\n",
    "\n",
    "csv_file1 = \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\"\n",
    "csv_file2 = \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\"\n",
    "\n",
    "for index, row in identical_pairs_images_df.iterrows():\n",
    "    image_name = row[\"Image folder location\"]\n",
    "    \n",
    "    df1 = pd.read_csv(csv_file1)\n",
    "    if image_name in df1[\"Image folder location\"].values:\n",
    "        matching_row = df1[df1[\"Image folder location\"] == image_name]\n",
    "        row = pd.concat([row, matching_row], axis=1)\n",
    "    \n",
    "    df2 = pd.read_csv(csv_file2)\n",
    "    if image_name in df2[\"Image folder location\"].values:\n",
    "        matching_row = df2[df2[\"Image folder location\"] == image_name]\n",
    "        row = pd.concat([row, matching_row], axis=1)\n",
    "    \n",
    "    merged_df = merged_df.append(row, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"merged_identical_pairs_images.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "identical_pairs_file = \"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\"\n",
    "identical_pairs_df = pd.read_csv(identical_pairs_file)\n",
    "\n",
    "def find_original_row(image_name, original_csv_path):\n",
    "    original_df = pd.read_csv(original_csv_path)\n",
    "    matching_rows = original_df[original_df.columns[original_df.columns.str.strip() == \"Image Folder Location\"].tolist()[0]].str.contains(image_name)\n",
    "    return original_df[matching_rows]\n",
    "\n",
    "new_columns = [\"Original Row (nmredata)\", \"Original Row (with signals)\"]\n",
    "\n",
    "identical_pairs_df[new_columns[0]] = \"\"\n",
    "identical_pairs_df[new_columns[1]] = \"\"\n",
    "\n",
    "for index, row in identical_pairs_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "    \n",
    "    try:\n",
    "        original_nmredata_row = find_original_row(nmredata_image, \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\")\n",
    "        if not original_nmredata_row.empty:\n",
    "            identical_pairs_df.at[index, new_columns[0]] = original_nmredata_row.to_string(index=False)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        original_with_signals_row = find_original_row(with_signals_image, \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\")\n",
    "        if not original_with_signals_row.empty:\n",
    "            identical_pairs_df.at[index, new_columns[1]] = original_with_signals_row.to_string(index=False)\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "identical_pairs_df.to_csv(identical_pairs_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "identical_pairs_file = \"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\"\n",
    "identical_pairs_df = pd.read_csv(identical_pairs_file)\n",
    "\n",
    "def find_original_row(image_name, original_csv_path):\n",
    "    original_df = pd.read_csv(original_csv_path)\n",
    "    matching_rows = original_df[original_df[\"Image Folder location\"].str.contains(image_name, case=False, regex=False)]\n",
    "    return matching_rows\n",
    "\n",
    "new_columns = [\"Original Row (nmredata)\", \"Original Row (with signals)\"]\n",
    "\n",
    "identical_pairs_df[new_columns[0]] = \"\"\n",
    "identical_pairs_df[new_columns[1]] = \"\"\n",
    "\n",
    "for index, row in identical_pairs_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "    \n",
    "    try:\n",
    "        original_nmredata_row = find_original_row(nmredata_image, \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\")\n",
    "        if not original_nmredata_row.empty:\n",
    "            identical_pairs_df.at[index, new_columns[0]] = original_nmredata_row.to_string(index=False)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        original_with_signals_row = find_original_row(with_signals_image, \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\")\n",
    "        if not original_with_signals_row.empty:\n",
    "            identical_pairs_df.at[index, new_columns[1]] = original_with_signals_row.to_string(index=False)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "identical_pairs_df.to_csv(identical_pairs_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [

     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Image folder location'",
     "output_type": "error",
     "traceback": [
      "\u0
     ]
    }
   ],
   "source": [
    "identical_pairs_images_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "\n",
    "nmredata_csv = \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\"\n",
    "nmredata_df = pd.read_csv(nmredata_csv)\n",
    "\n",
    "with_signals_csv = \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\"\n",
    "with_signals_df = pd.read_csv(with_signals_csv)\n",
    "\n",
    "nmredata_image_map = nmredata_df.set_index(\"Image folder location\").to_dict()[\"Image folder location\"]\n",
    "with_signals_image_map = with_signals_df.set_index(\"Image folder location\").to_dict()[\"Image folder location\"]\n",
    "\n",
    "identical_pairs_images_df[\"nmredata_row\"] = \"\"\n",
    "identical_pairs_images_df[\"with_signals_row\"] = \"\"\n",
    "\n",
    "for index, row in identical_pairs_images_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "\n",
    "    if nmredata_image in nmredata_image_map:\n",
    "        identical_pairs_images_df.at[index, \"nmredata_row\"] = nmredata_image_map[nmredata_image]\n",
    "    \n",
    "    if with_signals_image in with_signals_image_map:\n",
    "        identical_pairs_images_df.at[index, \"with_signals_row\"] = with_signals_image_map[with_signals_image]\n",
    "\n",
    "identical_pairs_images_df.to_csv(\"identical_pairs_images.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30293/2437386172.py:7: DtypeWarning: Columns (11,13,14,15,16,17,18,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,43,44,46,48,49,51,52,53,54,55,56,57,58,60,63,65,66,69,70,71,72,75,76,77,78,79,82,83,86,87,88,89,90,91,94,95,96,97,98,102,104,105,108,109,110,111,112,113,114,117,119,122,123,124,126,128,129,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,148,149,150,151,152,153,155,156,157,158,160,161,162,163,164,165,166,167,168,169,170,171,173,174,175,177,178,181,182,183,185,186,187,188,190,193,195,196,198,199,203,204,205,208,210,212,213,214,215,216,217,218,219,220,221,222,234,235,236,237,238,239,240,241,242,243,244,245,247,251,252,253,255,256,257,258,259,260,262,265,268,269,270,273,278,282,283,288,289,290,291,293,294,295,296,298,300) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  with_signals_df = pd.read_csv(with_signals_csv)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Image folder location'",
     "output_type": "error",
     "traceback": [
    
     ]
    }
   ],
   "source": [
    "identical_pairs_images_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "\n",
    "nmredata_csv = \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\"\n",
    "nmredata_df = pd.read_csv(nmredata_csv)\n",
    "\n",
    "with_signals_csv = \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\"\n",
    "with_signals_df = pd.read_csv(with_signals_csv)\n",
    "\n",
    "nmredata_image_map = nmredata_df.set_index(\"Image folder location\").to_dict()[\"Image folder location\"]\n",
    "with_signals_image_map = with_signals_df.set_index(\"Image folder location\").to_dict()[\"Image folder location\"]\n",
    "\n",
    "identical_pairs_images_df[\"nmredata_row\"] = \"\"\n",
    "identical_pairs_images_df[\"with_signals_row\"] = \"\"\n",
    "\n",
    "for index, row in identical_pairs_images_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "\n",
    "    if nmredata_image in nmredata_image_map:\n",
    "        identical_pairs_images_df.at[index, \"nmredata_row\"] = nmredata_image_map[nmredata_image]\n",
    "    \n",
    "    if with_signals_image in with_signals_image_map:\n",
    "        identical_pairs_images_df.at[index, \"with_signals_row\"] = with_signals_image_map[with_signals_image]\n",
    "\n",
    "identical_pairs_images_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\", index=False)\n",
    "\n",
    "for index, row in identical_pairs_images_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "\n",
    "    print(f\"Processing row {index + 1}\")\n",
    "    print(f\"nmredata_image: '{nmredata_image}'\")\n",
    "    print(f\"with_signals_image: '{with_signals_image}'\")\n",
    "\n",
    "    if nmredata_image in nmredata_image_map:\n",
    "        identical_pairs_images_df.at[index, \"nmredata_row\"] = nmredata_image_map[nmredata_image]\n",
    "        print(\"Match found in nmredata_image_map\")\n",
    "\n",
    "    if with_signals_image in with_signals_image_map:\n",
    "        identical_pairs_images_df.at[index, \"with_signals_row\"] = with_signals_image_map[with_signals_image]\n",
    "        print(\"Match found in with_signals_image_map\")\n",
    "    else:\n",
    "        print(\"No match found in with_signals_image_map\")\n",
    "\n",
    "identical_pairs_images_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Original Row'",
     "output_type": "error",
     "traceback": [
     
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the identical_pairs_images.csv file\n",
    "identical_pairs_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "\n",
    "# Load the nmredata CSV file\n",
    "nmredata_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\")\n",
    "\n",
    "# Load the with signals CSV file\n",
    "with_signals_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\")\n",
    "\n",
    "# Initialize new columns\n",
    "identical_pairs_df[\"Original row nrmedata\"] = \"\"\n",
    "identical_pairs_df[\"Original row with signals\"] = \"\"\n",
    "\n",
    "# Create dictionaries to map image names to their respective row numbers\n",
    "nmredata_image_map = nmredata_df.set_index(\"Image folder location\")[\"Original Row\"].to_dict()\n",
    "with_signals_image_map = with_signals_df.set_index(\"Image folder location\")[\"Original Row\"].to_dict()\n",
    "\n",
    "# Iterate through each row in identical_pairs_df and fill in the new columns\n",
    "for index, row in identical_pairs_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "\n",
    "    # Check if the image names exist in the respective dictionaries\n",
    "    if nmredata_image in nmredata_image_map:\n",
    "        identical_pairs_df.at[index, \"Original row nrmedata\"] = nmredata_image_map[nmredata_image]\n",
    "    \n",
    "    if with_signals_image in with_signals_image_map:\n",
    "        identical_pairs_df.at[index, \"Original row with signals\"] = with_signals_image_map[with_signals_image]\n",
    "\n",
    "# Save the updated DataFrame to identical_pairs_images.csv\n",
    "identical_pairs_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the identical_pairs_images.csv file\n",
    "identical_pairs_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "\n",
    "# Load the nmredata CSV file\n",
    "nmredata_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\")\n",
    "\n",
    "# Load the with signals CSV file\n",
    "with_signals_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\")\n",
    "\n",
    "# Initialize new columns\n",
    "identical_pairs_df[\"Original row nrmedata\"] = \"\"\n",
    "identical_pairs_df[\"Original row with signals\"] = \"\"\n",
    "\n",
    "# Iterate through each row in identical_pairs_df and fill in the new columns\n",
    "for index, row in identical_pairs_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "\n",
    "    # Initialize variables to store original row numbers\n",
    "    original_row_nrmedata = \"\"\n",
    "    original_row_with_signals = \"\"\n",
    "\n",
    "    # Iterate through columns in nmredata_df to find a match\n",
    "    for column in nmredata_df.columns:\n",
    "        if nmredata_image in column:\n",
    "            original_row_nrmedata = nmredata_df.at[index, column]\n",
    "            break  # Exit the loop if a match is found\n",
    "\n",
    "    # Iterate through columns in with_signals_df to find a match\n",
    "    for column in with_signals_df.columns:\n",
    "        if with_signals_image in column:\n",
    "            original_row_with_signals = with_signals_df.at[index, column]\n",
    "            break  # Exit the loop if a match is found\n",
    "\n",
    "    # Fill in the new columns with the original row numbers\n",
    "    identical_pairs_df.at[index, \"Original row nrmedata\"] = original_row_nrmedata\n",
    "    identical_pairs_df.at[index, \"Original row with signals\"] = original_row_with_signals\n",
    "\n",
    "# Save the updated DataFrame to identical_pairs_images.csv\n",
    "identical_pairs_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30293/969553470.py:12: DtypeWarning: Columns (11,13,14,15,16,17,18,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,43,44,46,48,49,51,52,53,54,55,56,57,58,60,63,65,66,69,70,71,72,75,76,77,78,79,82,83,86,87,88,89,90,91,94,95,96,97,98,102,104,105,108,109,110,111,112,113,114,117,119,122,123,124,126,128,129,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,148,149,150,151,152,153,155,156,157,158,160,161,162,163,164,165,166,167,168,169,170,171,173,174,175,177,178,181,182,183,185,186,187,188,190,193,195,196,198,199,203,204,205,208,210,212,213,214,215,216,217,218,219,220,221,222,234,235,236,237,238,239,240,241,242,243,244,245,247,251,252,253,255,256,257,258,259,260,262,265,268,269,270,273,278,282,283,288,289,290,291,293,294,295,296,298,300) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  with_signals_df = pd.read_csv(with_signals_csv)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the identical_pairs_images.csv file into a DataFrame\n",
    "identical_pairs_images_df = pd.read_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\")\n",
    "\n",
    "# Define the paths to the origin CSV files\n",
    "nmredata_csv = \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\"\n",
    "with_signals_csv = \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\"\n",
    "\n",
    "# Load the origin CSV files into DataFrames\n",
    "nmredata_df = pd.read_csv(nmredata_csv)\n",
    "with_signals_df = pd.read_csv(with_signals_csv)\n",
    "\n",
    "# Initialize new columns for the original row numbers\n",
    "identical_pairs_images_df[\"Original row nrmedata\"] = \"\"\n",
    "identical_pairs_images_df[\"Original row with signals\"] = \"\"\n",
    "\n",
    "# Iterate through each row in identical_pairs_images_df\n",
    "for index, row in identical_pairs_images_df.iterrows():\n",
    "    nmredata_image = row[\"nmredata\"]\n",
    "    with_signals_image = row[\"with signals\"]\n",
    "\n",
    "    # Find the original row number in nmredata_df\n",
    "    for nmredata_index, nmredata_row in nmredata_df.iterrows():\n",
    "        if nmredata_image in nmredata_row.values:\n",
    "            identical_pairs_images_df.at[index, \"Original row nrmedata\"] = nmredata_index\n",
    "            break  # Exit the loop after finding the first match\n",
    "\n",
    "    # Find the original row number in with_signals_df\n",
    "    for with_signals_index, with_signals_row in with_signals_df.iterrows():\n",
    "        if with_signals_image in with_signals_row.values:\n",
    "            identical_pairs_images_df.at[index, \"Original row with signals\"] = with_signals_index\n",
    "            break  # Exit the loop after finding the first match\n",
    "\n",
    "# Save the updated DataFrame to identical_pairs_images.csv\n",
    "identical_pairs_images_df.to_csv(\"datasets/processed/nmrshiftdb2/identical_pairs_images.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urban files: AG VB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gekaufte Substanzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_raw.txt\"\n",
    "output_file = \"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_extracted.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = [] \n",
    "pattern = r\"^VB-\\d{4}\"\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(pattern, line):\n",
    "        ids.append(line.strip())\n",
    "        \n",
    "        if i >= 2:\n",
    "            compound_name = lines[i - 2].strip()\n",
    "        else:\n",
    "            compound_name = \"\"\n",
    "        compound_names.append(compound_name)\n",
    "\n",
    "data = [{\"ID\": id_value, \"compound name\": comp_name} for id_value, comp_name in zip(ids, compound_names)]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Extracted data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional columns added to datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_extracted.csv\"\n",
    "output_file = \"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "solvent = \"d6DMSO\"\n",
    "nmr_type = \"1H, 13C\"\n",
    "pdf_file_path_template = \"datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/Gekaufte Substanzen/VB-XXX.pdf\"\n",
    "\n",
    "with open(input_file, \"r\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        ids.append(row[\"ID\"])\n",
    "        compound_names.append(row[\"compound name\"])\n",
    "\n",
    "updated_data = []\n",
    "for i in range(len(ids)):\n",
    "    updated_data.append({\n",
    "        \"ID\": ids[i],\n",
    "        \"compound name\": compound_names[i],\n",
    "        \"Solvent\": solvent,\n",
    "        \"NMR-Type\": nmr_type,\n",
    "        \"PDF file path\": pdf_file_path_template.replace(\"XXX\", ids[i].split('-')[1])\n",
    "    })\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\", \"Solvent\", \"NMR-Type\", \"PDF file path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_data)\n",
    "\n",
    "print(f\"Additional columns added to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES added to datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\n"
     ]
    }
   ],
   "source": [
    "cir_base_url = \"https://cactus.nci.nih.gov/chemical/structure\"\n",
    "\n",
    "input_csv_file = \"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "smiles_list = []\n",
    "\n",
    "for iupac_name in df[\"compound name\"]:\n",
    "    response = requests.get(f\"{cir_base_url}/{iupac_name}/smiles\")\n",
    "    if response.status_code == 200:\n",
    "        smiles = response.text\n",
    "        smiles_list.append(smiles)\n",
    "    else:\n",
    "        smiles_list.append(\"Unable to retrieve SMILES\")\n",
    "\n",
    "df.insert(df.columns.get_loc(\"compound name\") + 1, \"SMILES\", smiles_list)\n",
    "\n",
    "df.to_csv(input_csv_file, index=False)\n",
    "\n",
    "print(f\"SMILES added to {input_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_raw.txt\"\n",
    "output_file = \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_extracted.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "\n",
    "pattern = r\"^VB-\\d{3}\"\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(pattern, line):\n",
    "        ids.append(line.strip())\n",
    "        \n",
    "        if i >= 2:\n",
    "            compound_name = lines[i - 2].strip()\n",
    "        else:\n",
    "            compound_name = \"\"\n",
    "        compound_names.append(compound_name)\n",
    "\n",
    "data = [{\"ID\": id_value, \"compound name\": comp_name} for id_value, comp_name in zip(ids, compound_names)]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Extracted data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional columns added to datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_extracted.csv\"\n",
    "output_file = \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "solvent = \"d6DMSO\"\n",
    "nmr_type = \"1H, 13C\"\n",
    "pdf_file_path_template = \"datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-XXX.pdf\"\n",
    "\n",
    "with open(input_file, \"r\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        ids.append(row[\"ID\"])\n",
    "        compound_names.append(row[\"compound name\"])\n",
    "\n",
    "\n",
    "updated_data = []\n",
    "for i in range(len(ids)):\n",
    "    updated_data.append({\n",
    "        \"ID\": ids[i],\n",
    "        \"compound name\": compound_names[i],\n",
    "        \"Solvent\": solvent,\n",
    "        \"NMR-Type\": nmr_type,\n",
    "        \"PDF file path\": pdf_file_path_template.replace(\"XXX\", ids[i].split('-')[1])\n",
    "    })\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\", \"Solvent\", \"NMR-Type\", \"PDF file path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_data)\n",
    "\n",
    "print(f\"Additional columns added to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES added to datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n"
     ]
    }
   ],
   "source": [
    "cir_base_url = \"https://cactus.nci.nih.gov/chemical/structure\"\n",
    "\n",
    "input_csv_file = \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "smiles_list = []\n",
    "\n",
    "for iupac_name in df[\"compound name\"]:\n",
    "    response = requests.get(f\"{cir_base_url}/{iupac_name}/smiles\")\n",
    "    if response.status_code == 200:\n",
    "        smiles = response.text\n",
    "        smiles_list.append(smiles)\n",
    "    else:\n",
    "        smiles_list.append(\"Unable to retrieve SMILES\")\n",
    "\n",
    "df.insert(df.columns.get_loc(\"compound name\") + 1, \"SMILES\", smiles_list)\n",
    "\n",
    "df.to_csv(input_csv_file, index=False)\n",
    "\n",
    "print(f\"SMILES added to {input_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VB-JK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_raw.txt\"\n",
    "output_file = \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_extracted.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "\n",
    "pattern_id = r\"^VB-JK\\d{3}\"\n",
    "\n",
    "pattern_compound = r\"^(.*)\\s+\\(X{0,2}\\d{1,2}\\)$\"\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(pattern_id, line):\n",
    "        ids.append(line.strip())\n",
    "        \n",
    "        if i >= 2:\n",
    "            match = re.match(pattern_compound, lines[i - 2].strip())\n",
    "            if match:\n",
    "                compound_name = match.group(1)\n",
    "            else:\n",
    "                compound_name = \"\"\n",
    "        else:\n",
    "            compound_name = \"\"\n",
    "        compound_names.append(compound_name)\n",
    "\n",
    "data = [{\"ID\": id_value, \"compound name\": comp_name} for id_value, comp_name in zip(ids, compound_names)]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Extracted data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional columns added to datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_extracted.csv\"\n",
    "output_file = \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "solvent = \"d6DMSO\"\n",
    "nmr_type = \"1H, 13C\"\n",
    "pdf_file_path_template = \"datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-XXX.pdf\"\n",
    "\n",
    "with open(input_file, \"r\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        ids.append(row[\"ID\"])\n",
    "        compound_names.append(row[\"compound name\"])\n",
    "\n",
    "\n",
    "updated_data = []\n",
    "for i in range(len(ids)):\n",
    "    updated_data.append({\n",
    "        \"ID\": ids[i],\n",
    "        \"compound name\": compound_names[i],\n",
    "        \"Solvent\": solvent,\n",
    "        \"NMR-Type\": nmr_type,\n",
    "        \"PDF file path\": pdf_file_path_template.replace(\"XXX\", ids[i].split('-')[1])\n",
    "    })\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\", \"Solvent\", \"NMR-Type\", \"PDF file path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_data)\n",
    "\n",
    "print(f\"Additional columns added to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES added to datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n"
     ]
    }
   ],
   "source": [
    "cir_base_url = \"https://cactus.nci.nih.gov/chemical/structure\"\n",
    "\n",
    "input_csv_file = \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "smiles_list = []\n",
    "\n",
    "for iupac_name in df[\"compound name\"]:\n",
    "    response = requests.get(f\"{cir_base_url}/{iupac_name}/smiles\")\n",
    "    if response.status_code == 200:\n",
    "        smiles = response.text\n",
    "        smiles_list.append(smiles)\n",
    "    else:\n",
    "        smiles_list.append(\"Unable to retrieve SMILES\")\n",
    "\n",
    "df.insert(df.columns.get_loc(\"compound name\") + 1, \"SMILES\", smiles_list)\n",
    "\n",
    "df.to_csv(input_csv_file, index=False)\n",
    "\n",
    "print(f\"SMILES added to {input_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AG Lubec Gert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MK: Kirchhofer Michael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_raw.txt\"\n",
    "output_file = \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_extracted.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "\n",
    "pattern_id = r\"^MK\\d{3}[\\w\\d-]*\"\n",
    "\n",
    "pattern_compound = r\"^(.*)$\"\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(pattern_id, line):\n",
    "        ids.append(line.strip())\n",
    "\n",
    "        if i >= 2 and i - 2 < len(lines):\n",
    "            compound_name = re.match(pattern_compound, lines[i - 2].strip())\n",
    "            if compound_name:\n",
    "                compound_names.append(compound_name.group(1))\n",
    "            else:\n",
    "                compound_names.append(\"\")\n",
    "\n",
    "data = [{\"ID\": id_value, \"compound name\": comp_name} for id_value, comp_name in zip(ids, compound_names)]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Extracted data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional columns added to datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_extracted.csv\"\n",
    "output_file = \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "solvent = \"cdcl3\"\n",
    "nmr_type = \"1H, 13C\"\n",
    "pdf_file_path_template = \"datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/MK - Kirchhofer Michael/{ID}.pdf\"\n",
    "\n",
    "with open(input_file, \"r\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        ids.append(row[\"ID\"])\n",
    "        compound_names.append(row[\"compound name\"])\n",
    "\n",
    "updated_data = []\n",
    "for i in range(len(ids)):\n",
    "    updated_data.append({\n",
    "        \"ID\": ids[i],\n",
    "        \"compound name\": compound_names[i],\n",
    "        \"Solvent\": solvent,\n",
    "        \"NMR-Type\": nmr_type,\n",
    "        \"PDF file path\": pdf_file_path_template.format(ID=ids[i])\n",
    "    })\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\", \"Solvent\", \"NMR-Type\", \"PDF file path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_data)\n",
    "\n",
    "print(f\"Additional columns added to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES added to datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv\n"
     ]
    }
   ],
   "source": [
    "cir_base_url = \"https://cactus.nci.nih.gov/chemical/structure\"\n",
    "\n",
    "input_csv_file = \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "smiles_list = []\n",
    "\n",
    "for iupac_name in df[\"compound name\"]:\n",
    "    response = requests.get(f\"{cir_base_url}/{iupac_name}/smiles\")\n",
    "    if response.status_code == 200:\n",
    "        smiles = response.text\n",
    "        smiles_list.append(smiles)\n",
    "    else:\n",
    "        smiles_list.append(\"Unable to retrieve SMILES\")\n",
    "\n",
    "df.insert(df.columns.get_loc(\"compound name\") + 1, \"SMILES\", smiles_list)\n",
    "\n",
    "df.to_csv(input_csv_file, index=False)\n",
    "\n",
    "print(f\"SMILES added to {input_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PN - Neill Philip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_raw.txt\"\n",
    "output_file = \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_extracted.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "\n",
    "pattern_id = r\"^PN\\d{3}[\\w\\d-]*\"\n",
    "\n",
    "pattern_compound = r\"^(.*)$\"\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(pattern_id, line):\n",
    "        ids.append(line.strip())\n",
    "\n",
    "        if i >= 2 and i - 2 < len(lines):\n",
    "            compound_name = re.match(pattern_compound, lines[i - 2].strip())\n",
    "            if compound_name:\n",
    "                compound_names.append(compound_name.group(1))\n",
    "            else:\n",
    "                compound_names.append(\"\")\n",
    "\n",
    "data = [{\"ID\": id_value, \"compound name\": comp_name} for id_value, comp_name in zip(ids, compound_names)]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Extracted data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional columns added to datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_extracted.csv\"\n",
    "output_file = \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "solvent = \"cdcl3\"\n",
    "nmr_type = \"1H, 13C\"\n",
    "pdf_file_path_template = \"datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/PN - Neill Philip/{ID}.pdf\"\n",
    "\n",
    "with open(input_file, \"r\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        ids.append(row[\"ID\"])\n",
    "        compound_names.append(row[\"compound name\"])\n",
    "\n",
    "updated_data = []\n",
    "for i in range(len(ids)):\n",
    "    updated_data.append({\n",
    "        \"ID\": ids[i],\n",
    "        \"compound name\": compound_names[i],\n",
    "        \"Solvent\": solvent,\n",
    "        \"NMR-Type\": nmr_type,\n",
    "        \"PDF file path\": pdf_file_path_template.format(ID=ids[i])\n",
    "    })\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\", \"Solvent\", \"NMR-Type\", \"PDF file path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_data)\n",
    "\n",
    "print(f\"Additional columns added to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES added to datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\n"
     ]
    }
   ],
   "source": [
    "cir_base_url = \"https://cactus.nci.nih.gov/chemical/structure\"\n",
    "\n",
    "input_csv_file = \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "smiles_list = []\n",
    "\n",
    "for iupac_name in df[\"compound name\"]:\n",
    "    response = requests.get(f\"{cir_base_url}/{iupac_name}/smiles\")\n",
    "    if response.status_code == 200:\n",
    "        smiles = response.text\n",
    "        smiles_list.append(smiles)\n",
    "    else:\n",
    "        smiles_list.append(\"Unable to retrieve SMILES\")\n",
    "\n",
    "df.insert(df.columns.get_loc(\"compound name\") + 1, \"SMILES\", smiles_list)\n",
    "\n",
    "df.to_csv(input_csv_file, index=False)\n",
    "\n",
    "print(f\"SMILES added to {input_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SB - Bittner Stefan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_raw.txt\"\n",
    "output_file = \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_extracted.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "\n",
    "pattern_id = r\"^SB\\d{3}[\\w\\d-]*\"\n",
    "\n",
    "pattern_compound = r\"^(.*)$\"\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if re.search(pattern_id, line):\n",
    "        ids.append(line.strip())\n",
    "\n",
    "        if i >= 2 and i - 2 < len(lines):\n",
    "            compound_name = re.match(pattern_compound, lines[i - 2].strip())\n",
    "            if compound_name:\n",
    "                compound_names.append(compound_name.group(1))\n",
    "            else:\n",
    "                compound_names.append(\"\")\n",
    "\n",
    "data = [{\"ID\": id_value, \"compound name\": comp_name} for id_value, comp_name in zip(ids, compound_names)]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Extracted data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional columns added to datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_extracted.csv\"\n",
    "output_file = \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv\"\n",
    "\n",
    "ids = []\n",
    "compound_names = []\n",
    "solvent = \"cdcl3\"\n",
    "nmr_type = \"1H, 13C\"\n",
    "pdf_file_path_template = \"datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/SB - Bittner Stefan/{ID}.pdf\"\n",
    "\n",
    "with open(input_file, \"r\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        ids.append(row[\"ID\"])\n",
    "        compound_names.append(row[\"compound name\"])\n",
    "\n",
    "updated_data = []\n",
    "for i in range(len(ids)):\n",
    "    updated_data.append({\n",
    "        \"ID\": ids[i],\n",
    "        \"compound name\": compound_names[i],\n",
    "        \"Solvent\": solvent,\n",
    "        \"NMR-Type\": nmr_type,\n",
    "        \"PDF file path\": pdf_file_path_template.format(ID=ids[i])\n",
    "    })\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"ID\", \"compound name\", \"Solvent\", \"NMR-Type\", \"PDF file path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_data)\n",
    "\n",
    "print(f\"Additional columns added to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES added to datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv\n"
     ]
    }
   ],
   "source": [
    "cir_base_url = \"https://cactus.nci.nih.gov/chemical/structure\"\n",
    "\n",
    "input_csv_file = \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "smiles_list = []\n",
    "\n",
    "for iupac_name in df[\"compound name\"]:\n",
    "    response = requests.get(f\"{cir_base_url}/{iupac_name}/smiles\")\n",
    "    if response.status_code == 200:\n",
    "        smiles = response.text\n",
    "        smiles_list.append(smiles)\n",
    "    else:\n",
    "        smiles_list.append(\"Unable to retrieve SMILES\")\n",
    "\n",
    "df.insert(df.columns.get_loc(\"compound name\") + 1, \"SMILES\", smiles_list)\n",
    "\n",
    "df.to_csv(input_csv_file, index=False)\n",
    "\n",
    "print(f\"SMILES added to {input_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning: Urban files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV File: datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/Gekaufte Substanzen/VB-1002 ident mit VB.pdf\n",
      "Row 2: ID                                    VB-1002 ident mit VB-1001 !!\n",
      "compound name            19F-NMR: -116,65 ppm (t, 10.6 Hz, Ph-F 3)\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 1, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv: 1\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-042 = VB.pdf\n",
      "Row 14: ID                                VB-042 = VB-057 + Verunreinigung\n",
      "compound name                                     * not detectable\n",
      "SMILES                                   Unable to retrieve SMILES\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 13, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-078.pdf\n",
      "Row 24: ID                                                      VB-078-Dry\n",
      "compound name                                                  NaN\n",
      "SMILES           CC(=O)N[C@@H]1[C@@H](O)C[C@](O)(O[C@H]1[C@H](O...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 23, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-128: NMRs in d6DMSO.pdf\n",
      "Row 25: ID                                          VB-128: NMRs in d6DMSO\n",
      "compound name                             tBuCH3\\tCH3\\t1,47\\t28,33\n",
      "SMILES                                   Unable to retrieve SMILES\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 24, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-091.pdf\n",
      "Row 34: ID                                                       VB-091-F1\n",
      "compound name    (4-(4-(ethylamino)-6-methylpyrimidin-2-yl)pipe...\n",
      "SMILES                  CCNc1cc(C)nc(n1)N2CCN(CC2)C(=O)c3ccc(I)cc3\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 33, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-078.pdf\n",
      "Row 54: ID                                       VB-078-Dry: NMRs in CDCl3\n",
      "compound name                             tBuCH3\\tCH3\\t1,40\\t28,02\n",
      "SMILES                                   Unable to retrieve SMILES\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 53, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-190b.pdf\n",
      "Row 100: ID                                                         VB-190b\n",
      "compound name        ethyl 2-(1-bromo-2-ethoxy-2-oxoethyl)benzoate\n",
      "SMILES                               CCOC(=O)C(Br)c1ccccc1C(=O)OCC\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 99, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-190f3.pdf\n",
      "Row 101: ID                                                      VB-190f3-5\n",
      "compound name        ethyl 2-(1-bromo-2-ethoxy-2-oxoethyl)benzoate\n",
      "SMILES                               CCOC(=O)C(Br)c1ccccc1C(=O)OCC\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 100, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-190f3.pdf\n",
      "Row 102: ID                                                      VB-190f3-5\n",
      "compound name                                                  NaN\n",
      "SMILES           CC(=O)N[C@@H]1[C@@H](O)C[C@](O)(O[C@H]1[C@H](O...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 101, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-267.pdf\n",
      "Row 150: ID                                                          VB-267\n",
      "compound name             4,4'-(chloromethylene)bis(chlorobenzene)\n",
      "SMILES                               ClC(c1ccc(Cl)cc1)c2ccc(Cl)cc2\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 149, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv: 9\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK173B.pdf\n",
      "Row 5: ID                                                       VB-JK173B\n",
      "compound name    N-ethyl-2-(4-((4-fluorophenyl)sulfonyl)piperaz...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 4, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK222.pdf\n",
      "Row 20: ID                                                        VB-JK222\n",
      "compound name    N-cyclopropyl-2-(4-((4-fluorophenyl)sulfonyl)p...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 19, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK235.pdf\n",
      "Row 25: ID                                                        VB-JK235\n",
      "compound name    4-(4-((4-fluorophenyl)sulfonyl)piperazin-1-yl)...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 24, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK312.pdf\n",
      "Row 46: ID                                                        VB-JK312\n",
      "compound name    (4-fluorophenyl)(4-(2-(isopropylamino)-6-methy...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 45, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK327.pdf\n",
      "Row 53: ID                                                        VB-JK327\n",
      "compound name    N-ethyl-2-(4-((2-fluoroethyl)sulfonyl)piperazi...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 52, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK355.pdf\n",
      "Row 58: ID                                                        VB-JK355\n",
      "compound name    N-(2-((4-(ethylamino)-6-methylpyrimidin-2-yl)a...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 57, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv: 6\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv: 0\n",
      "CSV File: datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/PN - Neill Philip/PN006-1.pdf\n",
      "Row 3: ID                                                         PN006-1\n",
      "compound name    2-(((phenyl(o-tolyl)methyl)sulfinyl)methyl)thi...\n",
      "SMILES                         Cc1ccccc1C(c2ccccc2)[S](=O)Cc3sccc3\n",
      "Solvent                                                      cdcl3\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 2, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/PN - Neill Philip/PN006-2.pdf\n",
      "Row 4: ID                                                         PN006-2\n",
      "compound name    2-(((phenyl(o-tolyl)methyl)sulfinyl)methyl)thi...\n",
      "SMILES                         Cc1ccccc1C(c2ccccc2)[S](=O)Cc3sccc3\n",
      "Solvent                                                      cdcl3\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 3, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv: 2\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv: 0\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv\"]  \n",
    "\n",
    "for csv_file in csv_files:\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    nonexistent_pdf_count = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        pdf_path = row['PDF file path']\n",
    "\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"CSV File: {csv_file}\")\n",
    "            print(f\"PDF file path does not exist: {pdf_path}\")\n",
    "            print(f\"Row {index + 1}: {row}\")\n",
    "            nonexistent_pdf_count += 1\n",
    "\n",
    "    print(f\"Total rows with nonexistent PDFs in {csv_file}: {nonexistent_pdf_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV File: datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/Gekaufte Substanzen/VB-1002 ident mit VB.pdf\n",
      "Row 2: ID                                    VB-1002 ident mit VB-1001 !!\n",
      "compound name            19F-NMR: -116,65 ppm (t, 10.6 Hz, Ph-F 3)\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 1, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv: 1\n",
      "Cleaned CSV saved as datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed_cleaned.csv\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-042 = VB.pdf\n",
      "Row 14: ID                                VB-042 = VB-057 + Verunreinigung\n",
      "compound name                                     * not detectable\n",
      "SMILES                                   Unable to retrieve SMILES\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 13, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-078.pdf\n",
      "Row 24: ID                                                      VB-078-Dry\n",
      "compound name                                                  NaN\n",
      "SMILES           CC(=O)N[C@@H]1[C@@H](O)C[C@](O)(O[C@H]1[C@H](O...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 23, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-128: NMRs in d6DMSO.pdf\n",
      "Row 25: ID                                          VB-128: NMRs in d6DMSO\n",
      "compound name                             tBuCH3\\tCH3\\t1,47\\t28,33\n",
      "SMILES                                   Unable to retrieve SMILES\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 24, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-091.pdf\n",
      "Row 34: ID                                                       VB-091-F1\n",
      "compound name    (4-(4-(ethylamino)-6-methylpyrimidin-2-yl)pipe...\n",
      "SMILES                  CCNc1cc(C)nc(n1)N2CCN(CC2)C(=O)c3ccc(I)cc3\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 33, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-078.pdf\n",
      "Row 54: ID                                       VB-078-Dry: NMRs in CDCl3\n",
      "compound name                             tBuCH3\\tCH3\\t1,40\\t28,02\n",
      "SMILES                                   Unable to retrieve SMILES\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 53, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-190b.pdf\n",
      "Row 100: ID                                                         VB-190b\n",
      "compound name        ethyl 2-(1-bromo-2-ethoxy-2-oxoethyl)benzoate\n",
      "SMILES                               CCOC(=O)C(Br)c1ccccc1C(=O)OCC\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 99, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-190f3.pdf\n",
      "Row 101: ID                                                      VB-190f3-5\n",
      "compound name        ethyl 2-(1-bromo-2-ethoxy-2-oxoethyl)benzoate\n",
      "SMILES                               CCOC(=O)C(Br)c1ccccc1C(=O)OCC\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 100, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-190f3.pdf\n",
      "Row 102: ID                                                      VB-190f3-5\n",
      "compound name                                                  NaN\n",
      "SMILES           CC(=O)N[C@@H]1[C@@H](O)C[C@](O)(O[C@H]1[C@H](O...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 101, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB- Battisti Verena/VB-267.pdf\n",
      "Row 150: ID                                                          VB-267\n",
      "compound name             4,4'-(chloromethylene)bis(chlorobenzene)\n",
      "SMILES                               ClC(c1ccc(Cl)cc1)c2ccc(Cl)cc2\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 149, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv: 9\n",
      "Cleaned CSV saved as datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed_cleaned.csv\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK173B.pdf\n",
      "Row 5: ID                                                       VB-JK173B\n",
      "compound name    N-ethyl-2-(4-((4-fluorophenyl)sulfonyl)piperaz...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 4, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK222.pdf\n",
      "Row 20: ID                                                        VB-JK222\n",
      "compound name    N-cyclopropyl-2-(4-((4-fluorophenyl)sulfonyl)p...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 19, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK235.pdf\n",
      "Row 25: ID                                                        VB-JK235\n",
      "compound name    4-(4-((4-fluorophenyl)sulfonyl)piperazin-1-yl)...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 24, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK312.pdf\n",
      "Row 46: ID                                                        VB-JK312\n",
      "compound name    (4-fluorophenyl)(4-(2-(isopropylamino)-6-methy...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 45, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK327.pdf\n",
      "Row 53: ID                                                        VB-JK327\n",
      "compound name    N-ethyl-2-(4-((2-fluoroethyl)sulfonyl)piperazi...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 52, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Battisti Verena/VB-JK - Kirchebner Julia/VB-JK355.pdf\n",
      "Row 58: ID                                                        VB-JK355\n",
      "compound name    N-(2-((4-(ethylamino)-6-methylpyrimidin-2-yl)a...\n",
      "Solvent                                                     d6DMSO\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 57, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv: 6\n",
      "Cleaned CSV saved as datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed_cleaned.csv\n",
      "CSV File: datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/PN - Neill Philip/PN006-1.pdf\n",
      "Row 3: ID                                                         PN006-1\n",
      "compound name    2-(((phenyl(o-tolyl)methyl)sulfinyl)methyl)thi...\n",
      "SMILES                         Cc1ccccc1C(c2ccccc2)[S](=O)Cc3sccc3\n",
      "Solvent                                                      cdcl3\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 2, dtype: object\n",
      "CSV File: datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\n",
      "PDF file path does not exist: datasets/raw/urban/Sicherung Ausw 2023-08-24/AG Lubec Gert/PN - Neill Philip/PN006-2.pdf\n",
      "Row 4: ID                                                         PN006-2\n",
      "compound name    2-(((phenyl(o-tolyl)methyl)sulfinyl)methyl)thi...\n",
      "SMILES                         Cc1ccccc1C(c2ccccc2)[S](=O)Cc3sccc3\n",
      "Solvent                                                      cdcl3\n",
      "NMR-Type                                                   1H, 13C\n",
      "PDF file path    datasets/raw/urban/Sicherung Ausw 2023-08-24/A...\n",
      "Name: 3, dtype: object\n",
      "Total rows with nonexistent PDFs in datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv: 2\n",
      "Cleaned CSV saved as datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed.csv\"]  \n",
    "\n",
    "for csv_file in csv_files:\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    nonexistent_pdf_count = 0\n",
    "\n",
    "    cleaned_rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        pdf_path = row['PDF file path']\n",
    "\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"CSV File: {csv_file}\")\n",
    "            print(f\"PDF file path does not exist: {pdf_path}\")\n",
    "            print(f\"Row {index + 1}: {row}\")\n",
    "            nonexistent_pdf_count += 1\n",
    "        else:\n",
    "            cleaned_rows.append(row)\n",
    "\n",
    "    print(f\"Total rows with nonexistent PDFs in {csv_file}: {nonexistent_pdf_count}\")\n",
    "\n",
    "    cleaned_df = pd.DataFrame(cleaned_rows, columns=df.columns)\n",
    "\n",
    "    cleaned_csv_file = csv_file.replace('.csv', '_cleaned.csv')\n",
    "    cleaned_df.to_csv(cleaned_csv_file, index=False)\n",
    "    print(f\"Cleaned CSV saved as {cleaned_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28813/1365473058.py:46: DtypeWarning: Columns (11,13,14,15,16,17,18,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,43,44,46,48,49,51,52,53,54,55,56,57,58,60,63,65,66,69,70,71,72,75,76,77,78,79,82,83,86,87,88,89,90,91,94,95,96,97,98,102,104,105,108,109,110,111,112,113,114,117,119,122,123,124,126,128,129,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,148,149,150,151,152,153,155,156,157,158,160,161,162,163,164,165,166,167,168,169,170,171,173,174,175,177,178,181,182,183,185,186,187,188,190,193,195,196,198,199,203,204,205,208,210,212,213,214,215,216,217,218,219,220,221,222,234,235,236,237,238,239,240,241,242,243,244,245,247,251,252,253,255,256,257,258,259,260,262,265,268,269,270,273,278,282,283,288,289,290,291,293,294,295,296,298,300) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "input_files = [ \n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-01.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-02.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-03.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-04.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-05.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-06.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-07.csv\",\n",
    "    \"datasets/processed/orts/iNEXT_Lib_1D/iNEXTG2-Plate-08.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/Gekaufte Substanzen/Gekaufte Substanzen_processed_cleaned.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/VB- Battisti Verena/VB_processed_cleaned.csv\",\n",
    "    \"datasets/processed/urban/AG Battisti Verena P/VB-JK - Kirchebner Julia/VB-JK_processed_cleaned.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/MK - Kirchhofer Michael/MK_processed.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/PN - Neill Philip/PN_processed_cleaned.csv\",\n",
    "    \"datasets/processed/urban/AG Lubec Gert P/SB - Bittner Stefan/SB_processed.csv\",\n",
    "    \"datasets/processed/nmrshiftdb2/nmredata/nmrshiftdb2.nmredata.csv\",\n",
    "    \"datasets/processed/nmrshiftdb2/withsignals/nmrshiftdb2withsignals.csv\"\n",
    "]\n",
    "\n",
    "output_folder = \"datasets/combined/\"\n",
    "\n",
    "last_assigned_id = {}\n",
    "\n",
    "dfs = []\n",
    "\n",
    "def generate_unique_id(row_index, folder_prefix):\n",
    "    if folder_prefix not in last_assigned_id:\n",
    "        last_assigned_id[folder_prefix] = 0\n",
    "    last_assigned_id[folder_prefix] += 1\n",
    "    return folder_prefix + str(last_assigned_id[folder_prefix]).zfill(5)\n",
    "\n",
    "for file_path in input_files:\n",
    "    if file_path.endswith(\".csv\"):\n",
    "        folder, filename = os.path.split(file_path)\n",
    "        folder_parts = folder.split(os.path.sep)\n",
    "        \n",
    "        for part in folder_parts:\n",
    "            if part in folder_prefixes:\n",
    "                folder_prefix = folder_prefixes[part]\n",
    "                break\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        df['Unique ID'] = [generate_unique_id(i, folder_prefix) for i in range(1, len(df) + 1)]\n",
    "        \n",
    "        dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "\n",
    "combined_df = combined_df[['Unique ID'] + [col for col in combined_df.columns if col != 'Unique ID']]\n",
    "\n",
    "combined_csv_path = os.path.join(output_folder, \"combined_all.csv\")\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"Unique ID\", \"ID\", \"Solvent\", \"SMILES\", \"NMR-Type\", \"SDF file path\",\n",
    "    \"PDF file path\", \"Image folder location\"\n",
    "]\n",
    "\n",
    "extracted_df = combined_df[columns_to_keep]\n",
    "\n",
    "extracted_csv_path = os.path.join(output_folder, \"combined_extracted.csv\")\n",
    "extracted_df.to_csv(extracted_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
